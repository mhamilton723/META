{
 "metadata": {
  "name": "",
  "signature": "sha256:282f20173c058e1f920228c3407834076927389e304cb36e9d37645aaa007b47"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import sys\n",
      "import numpy as np\n",
      "import hamilton_ml_mod as my\n",
      "import ml_param as param\n",
      "import ml_regressor_list as reglist\n",
      "reload(my); reload(reglist); reload(param)\n",
      "\n",
      "#parse data\n",
      "data=my.parser(param.data_file,param.feature_file,param.response_var)\n",
      "data=my.subsample(data,param.subsample)\n",
      "X=data[0]; Y=data[1]\n",
      "(X_train, X_test, Y_train, Y_test) = my.train_test_split(X, Y, test_size=param.test_size)\n",
      "\n",
      "#pickle data for use in other files\n",
      "saved_data = (X_train, X_test, Y_train, Y_test)\n",
      "my.pickler(saved_data,param.split_data_file)\n",
      "        \n",
      "#adjust dictionaries for sklearn pipeline\n",
      "[reglist.dim_reduce_params]=my.addstring([reglist.dim_reduce_params],'dim_reduce__')\n",
      "for i in reglist.param_space_list:\n",
      "    i=my.addstring(i,'reg__')\n",
      "    i=my.dictlist_add(i,reglist.dim_reduce_params)\n",
      "\n",
      "#create scorer\n",
      "sigNMAD=my.make_scorer(my.sigmaNMAD,greater_is_better=False)\n",
      "        \n",
      "print(\"Opening logfiles\"); sys.stdout.flush()\n",
      "with open(param.opt_verbose_file, \"w+\") as log_verbose, open(param.opt_best_file, \"w+\") as log_best:\n",
      "    \n",
      "    #perform grid search\n",
      "    grid_list=[]\n",
      "    for reg,param_space in zip(reglist.reg_list, reglist.param_space_list):\n",
      "        pipe=my.Pipeline([('inputer',reglist.imputer),('scaler',reglist.scaler),('dim_reduce',reglist.dim_reduce),('reg',reg)])  \n",
      "\n",
      "        print('Performing Grid Search with',pipe);sys.stdout.flush()\n",
      "        print('')\n",
      "        grid = my.GridSearchCV(pipe, param_space, cv=param.cv_folds, error_score=np.NaN, scoring=sigNMAD)\n",
      "        grid.fit(X_train, Y_train)\n",
      "        grid_list.append(grid)\n",
      "\n",
      "        print(\"Best parameters set found on development set:\")\n",
      "        print(grid.best_estimator_,file=log_best)\n",
      "        print(grid.best_estimator_)\n",
      "        print('',file=log_best)\n",
      "        print('')\n",
      "\n",
      "        for params, mean_score, scores in grid.grid_scores_:\n",
      "            print(\"%0.3f (+/-%0.03f) for %r\" % (\n",
      "                mean_score, scores.std() / 2, params),file=log_verbose )    \n",
      "\n",
      "my.pickler(grid_list,param.opt_pickle_file)\n",
      "print('Grid search pickled')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Metaparameters Read\n",
        "Data Subsampled"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Opening logfiles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Performing Grid Search with Pipeline(steps=[('inputer', Imputer(axis=0, copy=True, missing_values=-99, strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduce', PCA(copy=True, n_components=None, whiten=False)), ('reg', KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
        "      kernel_params=None))])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pipeline(steps=[('inputer', Imputer(axis=0, copy=True, missing_values=-99, strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduce', PCA(copy=True, n_components=15, whiten=True)), ('reg', KernelRidge(alpha=1, coef0=1, degree=2, gamma=None, kernel='poly',\n",
        "      kernel_params=None))])\n",
        "\n",
        "Performing Grid Search with Pipeline(steps=[('inputer', Imputer(axis=0, copy=True, missing_values=-99, strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduce', PCA(copy=True, n_components=None, whiten=False)), ('reg', SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pipeline(steps=[('inputer', Imputer(axis=0, copy=True, missing_values=-99, strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduce', PCA(copy=True, n_components=10, whiten=True)), ('reg', SVR(C=1, cache_size=200, coef0=1, degree=3, epsilon=0.1, gamma=1e-05,\n",
        "  kernel='sigmoid', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])\n",
        "\n",
        "Performing Grid Search with Pipeline(steps=[('inputer', Imputer(axis=0, copy=True, missing_values=-99, strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduce', PCA(copy=True, n_components=None, whiten=False)), ('reg', RandomForestRegressor(bootstrap=True, criterion='mse', max_de...timators=10, n_jobs=1, oob_score=False, random_state=None,\n",
        "           verbose=0, warm_start=False))])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best parameters set found on development set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pipeline(steps=[('inputer', Imputer(axis=0, copy=True, missing_values=-99, strategy='mean', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('dim_reduce', PCA(copy=True, n_components=15, whiten=True)), ('reg', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth...timators=50, n_jobs=1, oob_score=False, random_state=None,\n",
        "           verbose=0, warm_start=False))])\n",
        "\n",
        "Grid search pickled"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_verbose.close()\n",
      "log_best.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pipe\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-32-b051de97b773>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-b051de97b773>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print pipe\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}